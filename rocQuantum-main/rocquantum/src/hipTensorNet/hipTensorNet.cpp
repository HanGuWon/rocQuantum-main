#include "rocquantum/hipTensorNet.h"
#include "rocquantum/rocTensorUtil.h"
#include "rocquantum/Pathfinder.h"
#include <vector>
#include <map>
#include <algorithm>
#include <iostream>
#include <random>
#include <set>
#include <stdexcept>
#include <numeric>

// rocBLAS header
#include <rocblas/rocblas.h>
// rocSOLVER header
#include <rocsolver/rocsolver.h>


// C API struct
struct rocTnStruct {
    rocquantum::TensorNetworkBase* tn_instance;
};

namespace rocquantum {

// --- Slicing Data Structures (Placeholders) ---
struct SlicingInfo {
    int slicing_step_index = -1;
    size_t violating_size_bytes = 0;
    int tensor1_index = -1;
    int tensor2_index = -1;
};

struct SliceIndexInfo {
    std::string slice_label;
    long long slice_dimension = 0;
};


// --- Slicing Helper Functions (Stubs) ---

// Forward declarations for stub functions
template <typename T>
SlicingInfo findSlicingPoint(
    const internal::ContractionPlan& plan,
    size_t memory_limit_bytes);

template <typename T>
SliceIndexInfo selectSliceIndex(
    const internal::ContractionPlan& plan,
    int slicing_step_index);

template <typename T>
util::rocTensor executeSlicedContraction(
    const internal::ContractionPlan& plan,
    const SlicingInfo& slicing_info,
    const SliceIndexInfo& slice_index_info,
    const hipTensorNetContractionOptimizerConfig_t& config,
    rocblas_handle blas_handle,
    util::WorkspaceManager* workspace);


namespace util {
// Simple implementation of rocTensorFree, should be in rocTensorUtil.cpp
void rocTensorFree(rocTensor* tensor) {
    if (tensor && tensor->data_ && tensor->owned_) {
        hipFree(tensor->data_);
        tensor->data_ = nullptr;
    }
}
} // namespace util

// Core function to contract two tensors using rocBLAS
template <typename T>
rocqStatus_t rocTensorContractWithRocBLAS(
    const util::rocTensor& tensor_a,
    const util::rocTensor& tensor_b,
    const std::vector<std::pair<int, int>>& mode_pairs,
    util::rocTensor* result_tensor,
    rocblas_handle blas_handle,
    util::WorkspaceManager* workspace,
    hipStream_t stream) {

    // Step 1: Determine the dimensions and labels for the permutation.
    // The goal is to reshape tensor_a and tensor_b into 2D matrices for GEMM.
    // Matrix A will have shape (M, K) and Matrix B will have shape (K, N).
    // The result Matrix C will have shape (M, N).

    std::vector<long long> a_uncontracted_dims, b_uncontracted_dims, contracted_dims;
    std::vector<int> a_uncontracted_indices, b_uncontracted_indices, a_contracted_indices, b_contracted_indices;

    std::set<int> a_contracted_set, b_contracted_set;
    for(const auto& p : mode_pairs) {
        a_contracted_set.insert(p.first);
        b_contracted_set.insert(p.second);
    }

    long long M = 1, N = 1, K = 1;

    for(int i = 0; i < tensor_a.dims_.size(); ++i) {
        if(a_contracted_set.count(i)) {
            a_contracted_indices.push_back(i);
            K *= tensor_a.dims_[i];
        } else {
            a_uncontracted_indices.push_back(i);
            M *= tensor_a.dims_[i];
        }
    }

    for(int i = 0; i < tensor_b.dims_.size(); ++i) {
        if(b_contracted_set.count(i)) {
            b_contracted_indices.push_back(i);
        } else {
            b_uncontracted_indices.push_back(i);
            N *= tensor_b.dims_[i];
        }
    }
    
    // NEW Step 2: Define the permutation maps for GEMM reshaping.
    // The goal is to permute tensor_a to shape (M, K) and tensor_b to shape (K, N).
    std::vector<int> perm_map_a;
    perm_map_a.insert(perm_map_a.end(), a_uncontracted_indices.begin(), a_uncontracted_indices.end());
    perm_map_a.insert(perm_map_a.end(), a_contracted_indices.begin(), a_contracted_indices.end());

    std::vector<int> perm_map_b;
    perm_map_b.insert(perm_map_b.end(), b_contracted_indices.begin(), b_contracted_indices.end());
    perm_map_b.insert(perm_map_b.end(), b_uncontracted_indices.begin(), b_uncontracted_indices.end());

    // Step 3: Allocate workspace for permuted tensors (matrices A' and B')
    T* a_permuted_data = workspace->allocate<T>(M * K);
    T* b_permuted_data = workspace->allocate<T>(K * N);
    T* c_result_data = workspace->allocate<T>(M * N);

    // Step 4: Perform permutation using the new HIP kernel.
    launch_permute_tensor<T>(
        a_permuted_data,
        static_cast<const T*>(tensor_a.data_),
        tensor_a.dims_,
        perm_map_a,
        stream
    );
    launch_permute_tensor<T>(
        b_permuted_data,
        static_cast<const T*>(tensor_b.data_),
        tensor_b.dims_,
        perm_map_b,
        stream
    );

    // Step 5: Execute GEMM using rocBLAS.
    // We need to map the template type T to a rocblas_datatype.
    rocblas_datatype compute_type = (sizeof(T) == sizeof(rocComplex)) ? rocblas_datatype_f32_c : rocblas_datatype_f64_c;
    
    const T alpha = {1.0, 0.0}; // alpha = 1
    const T beta = {0.0, 0.0};  // beta = 0

    rocblas_status blas_status = rocblas_gemm_ex(blas_handle,
                                                 rocblas_operation_none, rocblas_operation_none,
                                                 M, N, K,
                                                 &alpha,
                                                 a_permuted_data, compute_type, M,
                                                 b_permuted_data, compute_type, K,
                                                 &beta,
                                                 c_result_data, compute_type, M,
                                                 c_result_data, compute_type, M,
                                                 compute_type, rocblas_gemm_algo_standard, 0, 0);

    if (blas_status != rocblas_status_success) {
        workspace->reset();
        return ROCQ_STATUS_EXECUTION_FAILED;
    }

    // Step 6: Create the final result tensor.
    // Allocate memory for the final tensor on the GPU.
    result_tensor->num_elements_ = M * N;
    hipMalloc(&result_tensor->data_, result_tensor->num_elements_ * sizeof(T));
    hipMemcpy(result_tensor->data_, c_result_data, result_tensor->num_elements_ * sizeof(T), hipMemcpyDeviceToDevice);
    result_tensor->owned_ = true;

    // Set metadata for the result tensor.
    result_tensor->dims_.clear();
    result_tensor->labels_.clear();
    for(int idx : a_uncontracted_indices) {
        result_tensor->dims_.push_back(tensor_a.dims_[idx]);
        result_tensor->labels_.push_back(tensor_a.labels_[idx]);
    }
    for(int idx : b_uncontracted_indices) {
        result_tensor->dims_.push_back(tensor_b.dims_[idx]);
        result_tensor->labels_.push_back(tensor_b.labels_[idx]);
    }

    // Free workspace memory for the next operation.
    workspace->reset();

    return ROCQ_STATUS_SUCCESS;
}


// --- TensorNetwork Template Implementation ---

template <typename T>
TensorNetwork<T>::TensorNetwork(util::WorkspaceManager* external_workspace, hipStream_t stream) {
    if (external_workspace) {
        workspace_ = external_workspace;
        owns_workspace_ = false;
    } else {
        try {
            workspace_ = new util::WorkspaceManager(DEFAULT_WORKSPACE_SIZE_BYTES, stream);
            owns_workspace_ = true;
        } catch (...) {
            workspace_ = nullptr;
            owns_workspace_ = false;
        }
    }
}

template <typename T>
TensorNetwork<T>::~TensorNetwork() {
    if (owns_workspace_ && workspace_) {
        delete workspace_;
    }
    for(auto& t : intermediate_tensors_) {
        util::rocTensorFree(&t.second);
    }
}

template <typename T>
int TensorNetwork<T>::add_tensor(const util::rocTensor& tensor) {
    initial_tensors_.push_back(tensor);
    return static_cast<int>(initial_tensors_.size() - 1);
}

template <typename T>
rocqStatus_t TensorNetwork<T>::contract(const hipTensorNetContractionOptimizerConfig_t* config,
                                       util::rocTensor* result_tensor,
                                       rocblas_handle blas_handle,
                                       hipStream_t stream) {
    if (initial_tensors_.empty()) {
        return ROCQ_STATUS_INVALID_VALUE;
    }
    if (initial_tensors_.size() == 1) {
        *result_tensor = initial_tensors_[0];
        return ROCQ_STATUS_SUCCESS;
    }

    // 1. Generate the Contraction Plan
    Pathfinder pathfinder;
    internal::ContractionPlan plan = pathfinder.findOptimalPath(*this, *config);

    // 2. High-Level Slicing Orchestration
    if (config->memory_limit_bytes > 0) {
        SlicingInfo slicing_info = findSlicingPoint<T>(plan, config->memory_limit_bytes);

        if (slicing_info.slicing_step_index != -1) {
            // Slicing is required.
            SliceIndexInfo slice_index_info = selectSliceIndex<T>(plan, slicing_info.slicing_step_index);
            
            // The executeSlicedContraction function will perform the sliced part of the plan
            // and the rest of the plan will need to be executed after.
            // This is a simplified view; a full implementation would be more complex.
            try {
                 *result_tensor = executeSlicedContraction<T>(plan, slicing_info, slice_index_info, *config, blas_handle, workspace_);
                 return ROCQ_STATUS_SUCCESS;
            } catch (const std::runtime_error& e) {
                std::cerr << "Slicing execution failed: " << e.what() << std::endl;
                return ROCQ_STATUS_FAILURE;
            }
        }
    }

    // 3. Standard (Non-Sliced) Contraction Logic
    // This part executes the plan generated by the pathfinder without slicing.
    std::map<int, util::rocTensor> active_tensors_map;
    for(size_t i = 0; i < initial_tensors_.size(); ++i) {
        active_tensors_map[i] = initial_tensors_[i];
    }

    for (const auto& step : plan.steps) {
        util::rocTensor& tensor_a = active_tensors_map.at(step.tensor_index_1);
        util::rocTensor& tensor_b = active_tensors_map.at(step.tensor_index_2);

        // Find shared modes between the two tensors for contraction
        std::vector<std::pair<int, int>> mode_pairs;
        // ... logic to find mode_pairs based on tensor labels ...

        util::rocTensor contracted_tensor;
        rocqStatus_t status = rocTensorContractWithRocBLAS<T>(
            tensor_a, tensor_b, mode_pairs, &contracted_tensor, blas_handle, workspace_, stream);

        if (status != ROCQ_STATUS_SUCCESS) return status;

        // Store the new intermediate tensor
        int new_tensor_id = initial_tensors_.size() + intermediate_tensors_.size();
        intermediate_tensors_[new_tensor_id] = contracted_tensor;
        active_tensors_map[new_tensor_id] = contracted_tensor;

        // Remove the consumed tensors from the active map
        active_tensors_map.erase(step.tensor_index_1);
        active_tensors_map.erase(step.tensor_index_2);
    }

    if (active_tensors_map.size() != 1) {
        return ROCQ_STATUS_FAILURE; // Should be exactly one tensor left
    }

    *result_tensor = active_tensors_map.begin()->second;
    
    // Prevent double-freeing the final tensor
    intermediate_tensors_.erase(active_tensors_map.begin()->first);


    return ROCQ_STATUS_SUCCESS;
}


// --- Stub Implementations for Slicing ---

template <typename T>
SlicingInfo findSlicingPoint(
    const internal::ContractionPlan& plan,
    size_t memory_limit_bytes)
{
    std::map<int, util::rocTensor> active_tensors;
    for (size_t i = 0; i < plan.initial_tensors.size(); ++i) {
        active_tensors[i] = plan.initial_tensors[i];
    }

    for (size_t i = 0; i < plan.steps.size(); ++i) {
        const auto& step = plan.steps[i];
        const auto& tensor1 = active_tensors.at(step.tensor_index_1);
        const auto& tensor2 = active_tensors.at(step.tensor_index_2);

        // Calculate the size of the resulting tensor
        std::vector<long long> result_dims;
        std::vector<std::string> result_labels;
        
        // This logic should be consistent with how rocTensorContractWithRocBLAS calculates the result tensor shape.
        // For now, we assume a helper function or similar logic exists.
        // Simplified logic:
        std::set<std::string> labels1(tensor1.labels_.begin(), tensor1.labels_.end());
        std::set<std::string> labels2(tensor2.labels_.begin(), tensor2.labels_.end());
        std::set<std::string> contracted_labels;

        for(const auto& mode : step.contraction_modes) {
            contracted_labels.insert(mode.label);
        }

        for(size_t j = 0; j < tensor1.labels_.size(); ++j) {
            if(contracted_labels.find(tensor1.labels_[j]) == contracted_labels.end()) {
                result_labels.push_back(tensor1.labels_[j]);
                result_dims.push_back(tensor1.dims_[j]);
            }
        }
        for(size_t j = 0; j < tensor2.labels_.size(); ++j) {
            if(contracted_labels.find(tensor2.labels_[j]) == contracted_labels.end() && labels1.find(tensor2.labels_[j]) == labels1.end()) {
                result_labels.push_back(tensor2.labels_[j]);
                result_dims.push_back(tensor2.dims_[j]);
            }
        }

        size_t result_num_elements = 1;
        for(long long dim : result_dims) {
            result_num_elements *= dim;
        }
        
        size_t result_size_bytes = result_num_elements * sizeof(T);
        size_t tensor1_size_bytes = tensor1.num_elements_ * sizeof(T);
        size_t tensor2_size_bytes = tensor2.num_elements_ * sizeof(T);

        size_t required_memory = tensor1_size_bytes + tensor2_size_bytes + result_size_bytes;

        if (required_memory > memory_limit_bytes) {
            SlicingInfo info;
            info.slicing_step_index = i;
            info.violating_size_bytes = required_memory;
            info.tensor1_index = step.tensor_index_1;
            info.tensor2_index = step.tensor_index_2;
            return info;
        }

        // Update active tensors for the next step
        util::rocTensor new_tensor;
        new_tensor.dims_ = result_dims;
        new_tensor.labels_ = result_labels;
        new_tensor.num_elements_ = result_num_elements;
        new_tensor.data_ = nullptr; // No actual data needed for this simulation
        new_tensor.owned_ = false;

        int new_tensor_id = plan.initial_tensors.size() + i;
        active_tensors[new_tensor_id] = new_tensor;
        active_tensors.erase(step.tensor_index_1);
        active_tensors.erase(step.tensor_index_2);
    }

    return SlicingInfo{}; // Return empty info, indicating no slicing needed
}

template <typename T>
SliceIndexInfo selectSliceIndex(
    const internal::ContractionPlan& plan,
    int slicing_step_index)
{
    // Ensure the slicing_step_index is valid.
    if (slicing_step_index < 0 || slicing_step_index >= plan.steps.size()) {
        throw std::out_of_range("Slicing step index is out of bounds.");
    }

    // Retrieve the specific contraction step that violates the memory limit.
    const auto& step = plan.steps.at(slicing_step_index);

    // The candidates for slicing are the non-contracted ("free") indices of the
    // resulting intermediate tensor from this step. Their details are stored
    // directly in the ContractionStep.
    const auto& resulting_labels = step.resulting_labels;
    const auto& resulting_dims = step.resulting_dims;

    if (resulting_labels.empty()) {
        // This case occurs if the contraction results in a scalar, which has no indices to slice.
        throw std::runtime_error("No suitable index found for slicing because the contraction results in a scalar.");
    }

    // Heuristic: Find the index (label) corresponding to the largest dimension.
    // Slicing along the largest dimension typically provides the most significant
    // reduction in the size of the tensors being processed in each partial contraction.
    long long max_dim = 0;
    int best_label_idx = -1;

    for (size_t i = 0; i < resulting_dims.size(); ++i) {
        if (resulting_dims[i] > max_dim) {
            max_dim = resulting_dims[i];
            best_label_idx = i;
        }
    }

    if (best_label_idx == -1) {
        // This is a fallback, in case all dimensions are 0 or 1.
        // We can just pick the first index.
        best_label_idx = 0;
        max_dim = resulting_dims[0];
    }

    // Populate the return struct with the chosen label and its dimension.
    SliceIndexInfo slice_info;
    slice_info.slice_label = resulting_labels[best_label_idx];
    slice_info.slice_dimension = max_dim;

    return slice_info;
}

template <typename T>
util::rocTensor executeSlicedContraction(
    const internal::ContractionPlan& plan,
    const SlicingInfo& slicing_info,
    const SliceIndexInfo& slice_index_info,
    const hipTensorNetContractionOptimizerConfig_t& config,
    rocblas_handle blas_handle,
    util::WorkspaceManager* workspace)
{
    // This function orchestrates the sliced contraction.
    // 1. It computes intermediate tensors up to the slicing point.
    // 2. It iterates over the specified axis, performs partial contractions for each slice, and accumulates the result.
    // 3. It forms a new network with the result of the sliced contraction and the remaining tensors to complete the calculation.

    // --- Step 1: Execute the plan up to the slicing point ---
    std::map<int, util::rocTensor> active_tensors;
    std::map<int, util::rocTensor> intermediates_to_free; // Track intermediate tensors for memory cleanup

    for (size_t i = 0; i < plan.initial_tensors.size(); ++i) {
        active_tensors[i] = plan.initial_tensors[i];
    }

    for (int i = 0; i < slicing_info.slicing_step_index; ++i) {
        const auto& step = plan.steps[i];
        auto& tensor_a = active_tensors.at(step.tensor_index_1);
        auto& tensor_b = active_tensors.at(step.tensor_index_2);
        
        util::rocTensor intermediate_tensor;
        rocTensorContractWithRocBLAS<T>(tensor_a, tensor_b, step.contraction_modes, &intermediate_tensor, blas_handle, workspace);

        int new_tensor_id = plan.initial_tensors.size() + i;
        active_tensors[new_tensor_id] = intermediate_tensor;
        intermediates_to_free[new_tensor_id] = intermediate_tensor;

        active_tensors.erase(step.tensor_index_1);
        active_tensors.erase(step.tensor_index_2);
    }

    // --- Step 2: Perform the sliced contraction ---
    const auto& slicing_step = plan.steps[slicing_info.slicing_step_index];
    auto& tensor1 = active_tensors.at(slicing_info.tensor1_index);
    auto& tensor2 = active_tensors.at(slicing_info.tensor2_index);

    // Allocate the full result tensor for the sliced step on the GPU and initialize to zero.
    util::rocTensor sliced_step_result;
    sliced_step_result.labels_ = slicing_step.resulting_labels;
    sliced_step_result.dims_ = slicing_step.resulting_dims;
    sliced_step_result.num_elements_ = std::accumulate(sliced_step_result.dims_.begin(), sliced_step_result.dims_.end(), 1LL, std::multiplies<long long>());
    hipMalloc(&sliced_step_result.data_, sliced_step_result.num_elements_ * sizeof(T));
    hipMemset(sliced_step_result.data_, 0, sliced_step_result.num_elements_ * sizeof(T));
    sliced_step_result.owned_ = true;

    // Main slicing loop: iterate over the specified dimension.
    for (long long i = 0; i < slice_index_info.slice_dimension; ++i) {
        // Use the create_sliced_view utility to create a lightweight view for the current slice.
        // Check which tensor to slice via its label.
        util::rocTensor tensor_slice1 = tensor1;
        util::rocTensor tensor_slice2 = tensor2;
        
        auto it1 = std::find(tensor1.labels_.begin(), tensor1.labels_.end(), slice_index_info.slice_label);
        if (it1 != tensor1.labels_.end()) {
            util::TensorView<T> view = util::create_sliced_view<T>(tensor1, slice_index_info.slice_label, i);
            tensor_slice1 = view.to_rocTensor();
        } else {
            auto it2 = std::find(tensor2.labels_.begin(), tensor2.labels_.end(), slice_index_info.slice_label);
            if (it2 != tensor2.labels_.end()) {
                util::TensorView<T> view = util::create_sliced_view<T>(tensor2, slice_index_info.slice_label, i);
                tensor_slice2 = view.to_rocTensor();
            }
        }

        // Calculate the partial result.
        util::rocTensor partial_result;
        rocTensorContractWithRocBLAS<T>(tensor_slice1, tensor_slice2, slicing_step.contraction_modes, &partial_result, blas_handle, workspace);

        // Use the custom HIP kernel to accumulate the partial result into the correct slice of the full tensor.
        launch_accumulate_sliced_result<T>(sliced_step_result, partial_result, slice_index_info.slice_label, i, hipStreamDefault);
        
        // Free the device memory allocated for the partial result.
        util::rocTensorFree(&partial_result);
    }

    // --- Step 3: Execute the rest of the plan ---
    // Form a new TensorNetwork with the result of the sliced step and the remaining active tensors.
    active_tensors.erase(slicing_info.tensor1_index);
    active_tensors.erase(slicing_info.tensor2_index);
    
    // If there are no more steps to perform, the sliced result is the final result.
    if (slicing_info.slicing_step_index >= plan.steps.size() - 1) {
        for(auto const& [key, val] : intermediates_to_free) {
            util::rocTensorFree(&val);
        }
        return sliced_step_result;
    }

    TensorNetwork<T> remaining_tn(workspace, hipStreamDefault);
    remaining_tn.add_tensor(sliced_step_result);
    for (const auto& pair : active_tensors) {
        remaining_tn.add_tensor(pair.second);
    }

    // Recursively call the contract function to compute the rest of the network.
    util::rocTensor final_tensor;
    hipTensorNetContractionOptimizerConfig_t remaining_config = config;
    remaining_config.memory_limit_bytes = 0; // Prevent further slicing in subsequent calls.

    rocqStatus_t status = remaining_tn.contract(&remaining_config, &final_tensor, blas_handle, hipStreamDefault);

    // Clean up all intermediate tensors created in this function's scope.
    util::rocTensorFree(&sliced_step_result);
    for(auto const& [key, val] : intermediates_to_free) {
        util::rocTensorFree(&val);
    }

    if (status != ROCQ_STATUS_SUCCESS) {
        throw std::runtime_error("Contraction of the remaining network after slicing failed.");
    }

    return final_tensor;
}


// Explicit template instantiation
template class TensorNetwork<rocComplex>;
template class TensorNetwork<rocDoubleComplex>;

} // namespace rocquantum

// --- C-API Implementation ---
extern "C" {

rocqStatus_t rocTensorNetworkCreate(rocTensorNetworkHandle_t* handle, rocDataType_t dtype) {
    if (!handle) return ROCQ_STATUS_INVALID_VALUE;
    
    rocTnStruct* h = new (std::nothrow) rocTnStruct;
    if (!h) return ROCQ_STATUS_ALLOCATION_FAILED;

    try {
        if (dtype == ROC_DATATYPE_C64) {
            h->tn_instance = new rocquantum::TensorNetwork<rocComplex>();
        } else if (dtype == ROC_DATATYPE_C128) {
            h->tn_instance = new rocquantum::TensorNetwork<rocDoubleComplex>();
        } else {
            delete h;
            return ROCQ_STATUS_NOT_IMPLEMENTED;
        }
        *handle = h;
        return ROCQ_STATUS_SUCCESS;
    } catch (...) {
        delete h;
        return ROCQ_STATUS_ALLOCATION_FAILED;
    }
}

rocqStatus_t rocTensorNetworkDestroy(rocTensorNetworkHandle_t handle) {
    if (handle) {
        delete handle->tn_instance;
        delete handle;
    }
    return ROCQ_STATUS_SUCCESS;
}

rocqStatus_t rocTensorNetworkAddTensor(rocTensorNetworkHandle_t handle, const rocquantum::util::rocTensor* tensor) {
    if (!handle || !handle->tn_instance || !tensor) return ROCQ_STATUS_INVALID_VALUE;
    handle->tn_instance->add_tensor(*tensor);
    return ROCQ_STATUS_SUCCESS;
}

rocqStatus_t rocTensorNetworkContract(rocTensorNetworkHandle_t handle,
                                      const hipTensorNetContractionOptimizerConfig_t* config,
                                      rocquantum::util::rocTensor* result_tensor,
                                      rocblas_handle blas_handle,
                                      hipStream_t stream) {
    if (!handle || !handle->tn_instance || !config || !result_tensor) return ROCQ_STATUS_INVALID_VALUE;
    return handle->tn_instance->contract(config, result_tensor, blas_handle, stream);
}

// --- NEW SVD IMPLEMENTATION ---
rocqStatus_t rocTensorSVD(rocTensorNetworkHandle_t handle, 
                          rocquantum::util::rocTensor* U, 
                          rocquantum::util::rocTensor* S, 
                          rocquantum::util::rocTensor* V, 
                          const rocquantum::util::rocTensor* A) {
    if (A->rank() != 2) return ROCQ_STATUS_INVALID_VALUE;

    rocsolver_handle rocsolver_h;
    rocsolver_create_handle(&rocsolver_h);

    long long m = A->dimensions_[0];
    long long n = A->dimensions_[1];
    long long k = std::min(m, n);

    // Allocate U, S, V tensors
    U->dimensions_ = {m, k}; U->calculate_strides(); rocquantum::util::rocTensorAllocate(U);
    S->dimensions_ = {k}; S->calculate_strides(); rocquantum::util::rocTensorAllocate(S);
    V->dimensions_ = {k, n}; V->calculate_strides(); rocquantum::util::rocTensorAllocate(V);

    void* workspace_ptr = nullptr;
    size_t workspace_size = 0;

    // Switch based on data type
    if (handle->tn_instance->dtype == ROC_DATATYPE_C128) {
        rocsolver_dgesvd_bufferSize(rocsolver_h, 'S', 'S', m, n, &workspace_size);
        hipMalloc(&workspace_ptr, workspace_size);
        rocsolver_dgesvd(rocsolver_h, 'S', 'S', m, n, 
                         (rocDoubleComplex*)A->data_, m, 
                         (double*)S->data_, 
                         (rocDoubleComplex*)U->data_, m, 
                         (rocDoubleComplex*)V->data_, k, 
                         (rocDoubleComplex*)workspace_ptr, 
                         nullptr);
    } else if (handle->tn_instance->dtype == ROC_DATATYPE_C64) {
        rocsolver_cgesvd_bufferSize(rocsolver_h, 'S', 'S', m, n, &workspace_size);
        hipMalloc(&workspace_ptr, workspace_size);
        rocsolver_cgesvd(rocsolver_h, 'S', 'S', m, n, 
                         (rocComplex*)A->data_, m, 
                         (float*)S->data_, 
                         (rocComplex*)U->data_, m, 
                         (rocComplex*)V->data_, k, 
                         (rocComplex*)workspace_ptr, 
                         nullptr);
    } else {
        rocsolver_destroy_handle(rocsolver_h);
        return ROCQ_STATUS_NOT_IMPLEMENTED;
    }

    hipFree(workspace_ptr);
    rocsolver_destroy_handle(rocsolver_h);
    return ROCQ_STATUS_SUCCESS;
}
// --- END SVD IMPLEMENTATION ---

} // extern "C"